{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7198a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from data_plot import *\n",
    "from NLP_data_read import *\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size,num_steps=32,35 #num_steps the size of the sequence\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
    "# vocab：dict类型 整数的index 会转换成对应的word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0eff42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(b.tensor([0,2]),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9898c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "torch.Size([5, 2, 28])\n",
      "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "print(X)\n",
    "print(F.one_hot(X.T, 28).shape)\n",
    "print(F.one_hot(X, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e4d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size,num_hiddens,device):\n",
    "    num_inputs=num_outputs=vocab_size\n",
    "    #一個個詞通過one hot 變成向量之後，就會變成長為vocab size 的向量 ，所以mlp輸入的維度就是vocab的size\n",
    "    \n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape,device=device)*0.01\n",
    "        # initialization the parameter with mean=0 and sd=1\n",
    "        \n",
    "    W_xh=normal((num_inputs,num_hiddens)) # the weight from input to the hidden layer\n",
    "    W_hh=normal((num_hiddens,num_hiddens))# the weight from last step of hidden layer to current step\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "\n",
    "    W_hq=normal((num_hiddens,num_outputs))\n",
    "    b_q=torch.zeros(num_outputs,device=device)\n",
    "    params = [W_xh,W_hh,b_h,W_hq,b_q]\n",
    "    \n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f3bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )\n",
    "\n",
    "#initialization the hidden variable, because when we at beganing of step 0 ,we do not have perivious hidden variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5ec4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state,params):\n",
    "    #sate: initial hidden variable\n",
    "    W_xh,W_hh,b_h,W_hq,b_q=params\n",
    "    \n",
    "    H,=state\n",
    "    outputs=[]\n",
    "    for X in inputs:\n",
    "        H=torch.tanh(torch.mm(X,W_xh)\n",
    "                    +torch.mm(H,W_hh)\n",
    "                    +b_h)\n",
    "        Y=torch.mm(H,W_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs,dim=0),(H,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc4ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch: \n",
    "\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "                            #forward function\n",
    "    def __call__(self, X, state):# forward\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc41478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b795cbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, device, get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], device)\n",
    "Y, new_state = net(X.to(device), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f265a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    # prefix 给定的开头\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
